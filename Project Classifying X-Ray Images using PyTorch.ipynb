{"cells":[{"source":"Pneumonia is one of the leading respiratory illnesses worldwide, and its timely and accurate diagnosis is essential for effective treatment. Manually reviewing chest X-rays is a critical step in this process, and AI can provide valuable support by helping to expedite the assessment. In your role as a consultant data scientist, you will test the ability of a deep learning model to distinguish pneumonia cases from normal images of lungs in chest X-rays.\n\nBy fine-tuning a pre-trained convolutional neural network, specifically the ResNet-18 model, your task is to classify X-ray images into two categories: normal lungs and those affected by pneumonia. You can leverage its already trained weights and get an accurate classifier trained faster and with fewer resources.\n\n## The Data\n\n<img src=\"x-rays_sample.png\" align=\"center\"/>\n&nbsp\n\nYou have a dataset of chest X-rays that have been preprocessed for use with a ResNet-18 model. You can see a sample of 5 images from each category above. Upon unzipping the `chestxrays.zip` file (code provided below), you will find your dataset inside the `data/chestxrays` folder divided into `test` and `train` folders. \n\nThere are 150 training images and 50 testing images for each category, NORMAL and PNEUMONIA (300 and 100 in total). For your convenience, this data has already been loaded into a `train_loader` and a `test_loader` using the `DataLoader` class from the PyTorch library. ","metadata":{},"id":"85dc467a-5830-44c0-ab74-435be0e5593c","cell_type":"markdown"},{"source":"# Import required libraries\n# -------------------------\n# Data loading\nimport random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# Train model\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Evaluate model\nfrom torchmetrics import Accuracy, F1Score\n\n# Set random seeds for reproducibility\ntorch.manual_seed(101010)\nnp.random.seed(101010)\nrandom.seed(101010)","metadata":{"executionCancelledAt":null,"executionTime":5662,"lastExecutedAt":1754497290723,"lastExecutedByKernel":"de785fd2-62eb-444c-9c6d-c729387019d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required libraries\n# -------------------------\n# Data loading\nimport random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# Train model\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Evaluate model\nfrom torchmetrics import Accuracy, F1Score\n\n# Set random seeds for reproducibility\ntorch.manual_seed(101010)\nnp.random.seed(101010)\nrandom.seed(101010)"},"id":"cb1bedee-bcd5-4c80-a5ed-93df89af0295","cell_type":"code","execution_count":1,"outputs":[]},{"source":"import os\nimport zipfile\n\n# Unzip the data folder\nif not os.path.exists('data/chestxrays'):\n    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n        zip_ref.extractall('data')","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1754497290775,"lastExecutedByKernel":"de785fd2-62eb-444c-9c6d-c729387019d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import os\nimport zipfile\n\n# Unzip the data folder\nif not os.path.exists('data/chestxrays'):\n    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n        zip_ref.extractall('data')"},"id":"dd91680d-cb63-4876-9a51-4ee6bb250c7d","cell_type":"code","execution_count":2,"outputs":[]},{"source":"# Define the transformations to apply to the images for use with ResNet-18\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std =[0.229, 0.224, 0.225]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n\n# Apply the image transforms\ntrain_dataset = ImageFolder('data/chestxrays/train', transform=transform)\ntest_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset))","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1754497290831,"lastExecutedByKernel":"de785fd2-62eb-444c-9c6d-c729387019d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the transformations to apply to the images for use with ResNet-18\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std =[0.229, 0.224, 0.225]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n\n# Apply the image transforms\ntrain_dataset = ImageFolder('data/chestxrays/train', transform=transform)\ntest_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"},"id":"0cc5591a-8dc1-4d7f-88d2-3b1a59fb2a5f","cell_type":"code","execution_count":3,"outputs":[]},{"source":"# Load pretrained model\nresnet18 = models.resnet18(pretrained=True)\n\n# Freeze all layers\nfor param in resnet18.parameters():\n    param.requires_grad = False\n\n# Replace final layer with 1 output for binary classification\nnum_features = resnet18.fc.in_features\nresnet18.fc = nn.Linear(num_features, 1)\n\n# Unfreeze only the final layer\nfor param in resnet18.fc.parameters():\n    param.requires_grad = True\n\n# Move to device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresnet18 = resnet18.to(device)\n\n# Loss and optimizer (as per feedback)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(resnet18.fc.parameters(), lr=0.01)  # CORRIGIDO: lr = 0.01\n\n# Training for 3 epochs\nresnet18.train()\nfor epoch in range(3):\n    total_loss = 0.0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = resnet18(images).squeeze(1)  # [B] → [B]\n        loss = criterion(outputs, labels.float())  # CORRIGIDO: labels em float\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n    print(f\"Epoch {epoch+1}/3 - Loss: {total_loss:.4f}\")\n\n    #-------------------\n# Evaluate the model\n#-------------------\n\nmodel = resnet18\nmodel.eval()\n\naccuracy_metric = Accuracy(task=\"binary\").to(device)\nf1_metric = F1Score(task=\"binary\").to(device)\n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = model(inputs).squeeze(1)\n        preds = torch.sigmoid(outputs).round()  # Saída agora é 1 logit por imagem\n\n        all_preds.append(preds)\n        all_labels.append(labels)\n\nall_preds = torch.cat(all_preds)\nall_labels = torch.cat(all_labels)\n\ntest_accuracy = accuracy_metric(all_preds, all_labels).item()\ntest_f1_score = f1_metric(all_preds, all_labels).item()\n\nprint(f\"Test Accuracy: {test_accuracy:.3f}\")\nprint(f\"Test F1 Score: {test_f1_score:.3f}\")","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":59,"type":"stream"},"2":{"height":122,"type":"stream"}}},"id":"c99cf95b-83f3-49e4-9777-4e70736452d8","cell_type":"code","execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/repl/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/44.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"400ec7d53c9a47698922db574cb1ff93"},"application/json":{"n":0,"total":46830571,"elapsed":0.007055521011352539,"ncols":null,"nrows":null,"prefix":"","ascii":false,"unit":"B","unit_scale":true,"rate":null,"bar_format":null,"postfix":null,"unit_divisor":1024,"initial":0,"colour":null}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"Epoch 1/3 - Loss: 2.7830\nEpoch 2/3 - Loss: 1.7945\nEpoch 3/3 - Loss: 1.8398\nTest Accuracy: 0.580\nTest F1 Score: 0.704\n"}]},{"source":"### Below is the provided model evaluation code. Run the below cell to help you evaluate the accuracy and F1-score of your fine-tuned model.","metadata":{},"id":"70761893-e66f-40fe-8862-dac9b18a13ab","cell_type":"markdown"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}